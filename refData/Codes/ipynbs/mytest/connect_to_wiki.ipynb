{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b3f96d-b51a-4198-9a8e-43e0d7ab3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Any, Dict, List\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_ollama import OllamaLLM\n",
    "'''\n",
    "'''\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd33bab9-1cce-48ce-a6ce-c923883a16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d2e3d-f85d-417d-8d9f-5205bc1df244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48486796-a3cd-4481-8bce-cc338dfbdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentProcessor:\n",
    "    def __init__(self):\n",
    "        # HTML 符號替換映射\n",
    "        self.html_replacements = {\n",
    "            '\\n': '<br>',\n",
    "            '-': '&ndash;',\n",
    "            '\"': '&quot;',\n",
    "            \"'\": '&apos;',\n",
    "            '(': '&#40;',\n",
    "            ')': '&#41;',\n",
    "        }\n",
    "    \n",
    "    def split_pages(self, content: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        將內容按頁面分割並進行格式化\n",
    "        \n",
    "        Args:\n",
    "            content: 原始內容字符串\n",
    "        \n",
    "        Returns:\n",
    "            包含每個頁面信息的字典列表\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 使用 \\n\\n 分割頁面\n",
    "            pages = content.split('\\n\\n')\n",
    "            result = []\n",
    "            \n",
    "            for page in pages:\n",
    "                if page.startswith('Page:'):\n",
    "                    # 分離頁面標題和內容\n",
    "                    parts = page.split('\\nSummary: ', 1)\n",
    "                    if len(parts) == 2:\n",
    "                        title = parts[0].replace('Page: ', '')\n",
    "                        content = parts[1]\n",
    "                        \n",
    "                        # 處理HTML符號\n",
    "                        processed_content = self.replace_symbols(content)\n",
    "                        \n",
    "                        result.append({\n",
    "                            'title': title,\n",
    "                            'content': processed_content\n",
    "                        })\n",
    "            \n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"分割頁面時發生錯誤: {str(e)}\")\n",
    "            return []\n",
    "    \n",
    "    def replace_symbols(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        替換文本中的符號為HTML標籤\n",
    "        \n",
    "        Args:\n",
    "            text: 需要處理的文本\n",
    "        \n",
    "        Returns:\n",
    "            處理後的文本\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 使用預定義的替換規則\n",
    "            for symbol, html_tag in self.html_replacements.items():\n",
    "                text = text.replace(symbol, html_tag)\n",
    "            \n",
    "            # 處理特殊的Unicode字符\n",
    "            text = re.sub(r'\\u2060', '', text)  # 移除零寬不換行空格\n",
    "            \n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"替換符號時發生錯誤: {str(e)}\")\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9b44de-dee9-4e49-9710-5eeaf7aa5213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef main():\\n    # 使用示例\\n    processor = ContentProcessor()\\n\\n    # 測試內容\\n    test_content = \\'\\'\\'Page: BIOS\\nSummary: In computing, BIOS (, BY-oss, -\\u2060ohss; Basic Input/Output System...\\n\\nPage: BIOS interrupt call\\nSummary: BIOS implementations provide interrupts...\\'\\'\\'\\n\\n    # 處理內容\\n    pages = processor.split_pages(test_content)\\n\\n    # 輸出結果\\n    for page in pages:\\n        print(f\"\\n標題: {page[\\'title\\']}\")\\n        print(f\"內容: {page[\\'content\\'][:100]}...\")  # 只顯示前100個字符\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def main():\n",
    "    # 使用示例\n",
    "    processor = ContentProcessor()\n",
    "    \n",
    "    # 測試內容\n",
    "    test_content = '''Page: BIOS\n",
    "Summary: In computing, BIOS (, BY-oss, -\\u2060ohss; Basic Input/Output System...\n",
    "\n",
    "Page: BIOS interrupt call\n",
    "Summary: BIOS implementations provide interrupts...'''\n",
    "    \n",
    "    # 處理內容\n",
    "    pages = processor.split_pages(test_content)\n",
    "    \n",
    "    # 輸出結果\n",
    "    for page in pages:\n",
    "        print(f\"\\n標題: {page['title']}\")\n",
    "        print(f\"內容: {page['content'][:100]}...\")  # 只顯示前100個字符\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9aa4d02-0453-4f87-a1d2-402f80677123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bdd63dd-fcc3-46e5-adc8-4ea2ea5efdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_content = wikipedia.run(\"Bios programming\")\n",
    "# processor = ContentProcessor()\n",
    "# pages = processor.split_pages(raw_content)\n",
    "# for page in pages:\n",
    "#         print(f\"\\n標題: {page['title']}\")\n",
    "#         print(f\"內容: {page['content'][:100]}...\")  # 只顯示前100個字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6e352f-a7c8-4e58-8fbd-0d38bd050376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomWikiAPIWrapper(WikipediaAPIWrapper):\n",
    "    def _clean_html(self, html: str) -> str:\n",
    "        soup = BeautifulSoup(html, features=\"lxml\")\n",
    "        text = soup.get_text()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9277548-ddff-47fc-9614-41e120948f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMInitializer:\n",
    "    \"\"\"LLM模型初始化類\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def init_ollama_model(\n",
    "        self, \n",
    "        model: str = \"deepseek-r1:7b\",\n",
    "        base_url: str = \"http://localhost:11434\",\n",
    "        **kwargs\n",
    "    ) -> OllamaLLM:\n",
    "        \"\"\"初始化OllamaLLM模型\n",
    "        \n",
    "        Args:\n",
    "            model: Ollama模型名稱\n",
    "            base_url: Ollama服務URL\n",
    "            **kwargs: 額外的模型參數\n",
    "            \n",
    "        Returns:\n",
    "            初始化後的OllamaLLM實例\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return OllamaLLM(\n",
    "                model=model,\n",
    "                base_url=base_url,\n",
    "                **kwargs\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"OllamaLLM模型初始化失敗: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d82bb58c-65ff-461a-997e-f3417e4c6c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentSummarizer(ABC):\n",
    "    \"\"\"內容摘要基類\"\"\"\n",
    "    def __init__(self, llm: Any):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.llm = llm\n",
    "        \n",
    "        self.template = \"\"\"\n",
    "        Role: You are an experienced and well-skilled text summarizer.\n",
    "        Task:\n",
    "        Please summarize the following context:\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Please provide:\n",
    "        1. Abstract: A very short overview\n",
    "        2. Summarization Content (100-500 words):\n",
    "           a. Most important points\n",
    "           b. Extended content\n",
    "        \n",
    "        3. Use technical and formal style.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"context\"],\n",
    "            template=self.template\n",
    "        )\n",
    "        self.content_parser = ContentProcessor()\n",
    "        self.chain = self.prompt | self.llm\n",
    "        # self.chain = LLMChain(prompt=self.prompt, llm=self.llm, verbose=False, return_final_only=True)\n",
    "\n",
    "    # def llm_invoke\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_content(self, query: str) -> Optional[str]:\n",
    "        \"\"\"獲取要摘要的內容\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def generate_summary(self, content: str) -> Optional[str]:\n",
    "        \"\"\"生成內容摘要\"\"\"\n",
    "        try:\n",
    "            response = self.chain.invoke({\"context\": content},)\n",
    "            # query_str = self.template.format(context=content)\n",
    "            # response = self.llm.invoke(query_str)\n",
    "            return response #response.get(\"text\", \"\")  # 從回應中獲取文本\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"摘要生成失敗: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "class WikiSummarizer(ContentSummarizer):\n",
    "    \"\"\"Wikipedia內容摘要器\"\"\"\n",
    "    \n",
    "    def __init__(self, llm: Any):\n",
    "        super().__init__(llm)\n",
    "        self.wiki = CustomWikiAPIWrapper()\n",
    "        # self.wiki = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(), )\n",
    "        # self.wiki = WikipediaQueryRun(CustomWikiAPIWrapper())\n",
    "    \n",
    "    def get_content(self, query: str) -> Optional[str]:\n",
    "        \"\"\"從Wikipedia獲取內容\"\"\"\n",
    "        try:\n",
    "            # filtered_content = self.content_parser.split_pages(self.wiki.run(query))\n",
    "            return self.wiki.run(query)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Wikipedia檢索失敗: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    \n",
    "    def summarize(self, query: str) -> Optional[str]:\n",
    "        \"\"\"摘要Wikipedia內容\"\"\"\n",
    "        content = self.get_content(query)\n",
    "        if not content:\n",
    "            return None\n",
    "        return self.generate_summary(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52796a24-9cc9-451f-90bb-f4a369dc86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_main(query:str=None):\n",
    "    llm_init = LLMInitializer()\n",
    "    \n",
    "    try:\n",
    "        # 初始化deepseek-r1:7b模型\n",
    "        llm = llm_init.init_ollama_model(\n",
    "            model=\"deepseek-r1:7b\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        # 創建摘要器並使用\n",
    "        wiki_summarizer = WikiSummarizer(llm)\n",
    "        summary = wiki_summarizer.summarize(query)\n",
    "        filtered_summary = summary[summary.find(\"</think>\")+8:]\n",
    "        print(f\"查詢內容：{query}\\n回傳結果:\\n{filtered_summary}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "319dab5d-853a-4d53-a595-e89c4f2a6fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xrickliao/miniconda3/miniconda3/envs/llmenv/lib/python3.11/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/xrickliao/miniconda3/miniconda3/envs/llmenv/lib/python3.11/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查詢內容：AI\n",
      "回傳結果:\n",
      "\n",
      "\n",
      "### Summary of \"Artificial Intelligence\" Page:\n",
      "\n",
      "#### Abstract:\n",
      "The field of artificial intelligence (AI) involves the development of computational systems that mimic human intelligence to perform tasks such as learning, reasoning, problem-solving, perception, and decision-making. AI draws from various disciplines like computer science, mathematics, psychology, and linguistics. Its applications include web search engines, recommendation systems, virtual assistants, autonomous vehicles, generative tools, and strategy games. AI research has faced challenges such as \"AI winters\" due to funding issues but has recently seen growth with advancements in deep learning and transformer architectures. The future of AI is expected to be marked by rapid progress and increased investment.\n",
      "\n",
      "#### Summarization Content:\n",
      "\n",
      "1. **Most Important Points**:\n",
      "   - AI refers to computational systems designed to perform intelligent tasks.\n",
      "   - Applications include web search, recommendation systems, virtual assistants, autonomous vehicles, generative tools, and strategy games.\n",
      "   - AI research focuses on subfields like learning, reasoning, knowledge representation, planning, natural language processing, perception, and robotics.\n",
      "   - AI aims for general intelligence (superhuman-level performance) as a long-term goal.\n",
      "   - Historical context includes the establishment of AI as an academic discipline in 1956 and periods of funding loss (\"AI winters\").\n",
      "   - Recent advancements like deep learning and transformer architectures have revitalized interest in AI.\n",
      "\n",
      "2. **Extended Content**:\n",
      "   - AI has evolved through various subfields, each addressing specific goals and challenges. For example, natural language processing (NLP) enables machines to understand and generate human language, while robotics involves designing systems that can interact with physical environments.\n",
      "   - The field of AI is characterized by its interdisciplinary nature, integrating techniques such as search algorithms, mathematical optimization, formal logic, artificial neural networks, statistics, operations research, and economics. These tools enable AI systems to learn from data, make decisions, and solve complex problems.\n",
      "   - Historically, AI has faced significant challenges, including \"AI winters,\" periods of reduced funding and interest (e.g., in the mid-2000s). However, the field has seen a resurgence since 2012 with advancements in deep learning algorithms. The transformer architecture, introduced in 2017, marked a significant milestone as it outperformed previous AI techniques and spurred further innovation.\n",
      "   - The AI boom, driven by substantial investments from governments and corporations, has led to rapid progress in areas like generative AI (e.g., ChatGPT) and autonomous systems. However, this surge has also raised concerns about the potential harms of AI, including unintended consequences such as job displacement or ethical dilemmas.\n",
      "   - Despite its transformative potential, AI research continues to grapple with challenges related to bias, transparency, and accountability in algorithmic decision-making processes.\n",
      "\n",
      "### Summary of \".ai\" Page:\n",
      "\n",
      "#### Abstract:\n",
      "The `.ai` domain is the Internet country code top-level domain (ccTLD) for Anguilla, a British Overseas Territory in the Caribbean. Administered by the Anguilla government, `.ai` has gained prominence due to its association with artificial intelligence and technology-related projects. However, it is treated as a generic top-level domain (gTLD) by major registrars like Google because users often perceive it as too common for specific purposes.\n",
      "\n",
      "#### Summarization Content:\n",
      "\n",
      "1. **Most Important Points**:\n",
      "   - `.ai` is the ccTLD for Anguilla and is administered by its government.\n",
      "   - It has become a prominent domain name in the AI and technology sectors, reflecting its association with digital innovation and governance.\n",
      "   - Google treats `.ai` as a gTLD due to its perceived genericity, which impacts registration practices and pricing.\n",
      "\n",
      "2. **Extended Content**:\n",
      "   - The `.ai` domain is widely used by tech startups, research institutions, and organizations focused on artificial intelligence, machine learning, and digital technologies. It serves as a hub for projects ranging from AI tools and platforms to cutting-edge innovations in the field.\n",
      "   - Beyond its administrative role, `.ai` reflects the growing global interest in AI-driven solutions and governance in the Caribbean region. Its use highlights Anguilla's position as a regional leader in digital innovation and its contribution to the global AI ecosystem.\n",
      "   - The rise of `.ai` underscores the increasing intersection between geography, technology, and policy, particularly in the context of the digital revolution and its implications for local and international governance.\n"
     ]
    }
   ],
   "source": [
    "test_main(\"AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c43293-db08-4467-a2f9-4c377fceff26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cd45e9-2c03-41bd-935e-1ec0f1eeb39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
