{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a8f9a18-931c-49cc-aad2-24d1b5ed9e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境設置（需先安裝 llama-index-core 與 langchain）\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext, Settings\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "# from langchain_openai import ChatOpenAI\n",
    "import logging\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "015dae4d-ac28-43a5-8287-ecc7fd2efc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "# from llama_index.core.embeddings.mock_embed_model import MockEmbedding\n",
    "# from llama_index.core import Settings\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b453543-489e-4a7b-9d6a-a9b958f4f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6cab0660-160f-4e0d-989c-d49041ab8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMInitializer:\n",
    "    \"\"\"LLM模型初始化類\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def init_ollama_model(\n",
    "        self, \n",
    "        model: str = \"deepseek-r1:7b\",\n",
    "        base_url: str = \"http://localhost:11434\",\n",
    "        **kwargs\n",
    "    ) -> OllamaLLM:\n",
    "        \"\"\"初始化OllamaLLM模型\n",
    "        \n",
    "        Args:\n",
    "            model: Ollama模型名稱\n",
    "            base_url: Ollama服務URL\n",
    "            **kwargs: 額外的模型參數\n",
    "            \n",
    "        Returns:\n",
    "            初始化後的OllamaLLM實例\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return OllamaLLM(\n",
    "                model=model,\n",
    "                base_url=base_url,\n",
    "                streaming=True,\n",
    "                **kwargs\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"OllamaLLM模型初始化失敗: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "185d4350-47b7-4e28-9755-b9b919b7356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_model = SentenceTransformer(\"../.././../../../Embedding_Models/paraphrase-multilingual-MiniLM-L12-v2/\")\n",
    "# embed_model = SentenceTransformer(\"../.././../../../Embedding_Models/text2vec-base-chinese/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "789df143-3db3-48ba-9a4a-ec9e1384ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 自定義文件處理流程\n",
    "# def custom_embedding_pipeline(documents):\n",
    "#     # 生成嵌入向量\n",
    "#     texts = [doc.text for doc in documents]\n",
    "#     embeddings = embed_model.encode(texts, convert_to_tensor=False)\n",
    "#     # 建立 FAISS 索引\n",
    "#     dimension = embeddings.shape[1]\n",
    "#     faiss_index = faiss.IndexFlatL2(dimension)\n",
    "#     faiss_index.add(np.array(embeddings).astype('float32'))\n",
    "#     # 建立向量儲存上下文\n",
    "#     vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "#     storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "#     return storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bf27f43c-90be-4e7c-b235-9bcc2c5dfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修正後的嵌入流程與索引建立\n",
    "# 全局設定嵌入模型\n",
    "# Settings.embed_model = SentenceTransformer(\"shibing624/text2vec-base-chinese\")\n",
    "# Settings.embed_model=HuggingFaceEmbedding(model_name=\"../.././../../../Embedding_Models/text2vec-base-chinese/\")\n",
    "\n",
    "def custom_embedding_pipeline(documents):\n",
    "    persist_dir = \"./storage\"\n",
    "    os.makedirs(persist_dir, exist_ok=True)\n",
    "    # 显式生成嵌入向量\n",
    "    texts = [doc.text for doc in documents]\n",
    "    embeddings = Settings.embed_model.get_text_embedding_batch(texts)\n",
    "    \n",
    "    # 构建带嵌入的节点\n",
    "    nodes = [\n",
    "        TextNode(\n",
    "            text=doc.text, \n",
    "            embedding=emb,\n",
    "            metadata={\"source\": doc.metadata.get(\"file_name\", \"unknown\")}\n",
    "        ) \n",
    "        for doc, emb in zip(documents, embeddings)\n",
    "    ]\n",
    "    \n",
    "    # 验证嵌入维度\n",
    "    assert all(emb is not None for emb in embeddings), \"存在未生成嵌入的节点\"\n",
    "    dimension = len(embeddings[0])\n",
    "    \n",
    "    # 构建FAISS索引\n",
    "    faiss_index = faiss.IndexFlatL2(dimension)\n",
    "    faiss_index.add(np.array(embeddings).astype('float32'))\n",
    "    \n",
    "    # 创建存储上下文\n",
    "    vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_store,\n",
    "        persist_dir=persist_dir\n",
    "    )\n",
    "    # storage_context.persist(persist_dir=persist_dir,docstore_fname=\"docstore.json\",vector_store_fname=\"my_vector_store.json\")\n",
    "    storage_context.persist(persist_dir=persist_dir)\n",
    "    return storage_context\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f4b02-b2e9-4755-be93-dc480ba74058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LlamaIndex 建立法律條文索引系統\n",
    "legal_docs_dir = \"../../../misc/law\"\n",
    "# 載入文件\n",
    "legal_docs = SimpleDirectoryReader(legal_docs_dir).load_data()\n",
    "# 全局設定嵌入模型\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"shibing624/text2vec-base-chinese\",\n",
    "    embed_batch_size=32  # 最佳化批量處理\n",
    ")\n",
    "# 建立索引時移除 embed_model 參數\n",
    "# 自動處理嵌入生成\n",
    "legal_index = VectorStoreIndex.from_documents(\n",
    "    documents=legal_docs,\n",
    "    storage_context=custom_embedding_pipeline(legal_docs),\n",
    "    show_progress=True\n",
    ")\n",
    "# legal_index = VectorStoreIndex.from_documents(\n",
    "#     embed_model= MockEmbedding(embed_dim=1),\n",
    "#     documents=legal_docs,\n",
    "#     storage_context=custom_embedding_pipeline(legal_docs),\n",
    "#     show_progress=True\n",
    "# )\n",
    "\n",
    "query_engine = legal_index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "# 2. 封裝成 LangChain 工具\n",
    "def legal_retriever(query: str) -> str:\n",
    "    response = query_engine.query(query)\n",
    "    return str(response)\n",
    "\n",
    "legal_tool = Tool(\n",
    "    name=\"Legal Clause Retriever\",\n",
    "    func=legal_retriever,\n",
    "    description=\"檢索最新法律條文與司法解釋\"\n",
    ")\n",
    "\n",
    "# 3. LangChain 構建客服流程\n",
    "# llm = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0.3)\n",
    "llm = LLMInitializer()\n",
    "\n",
    "tools = [legal_tool]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"structured-chat-zero-shot-react-description\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 4. 整合應用範例\n",
    "response = agent.run(\n",
    "    \"用戶詢問合約中的不可抗力條款，請檢索民法相關規定並用台灣口語解釋\"\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160dfe8-15e4-40af-9664-fb9b076baa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tool = SQLDatabase.from_uri(\"sqlite:///contracts.db\")\n",
    "tools.append(db_tool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
